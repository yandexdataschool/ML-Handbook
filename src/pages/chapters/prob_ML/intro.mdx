---
title: Вероятностный подход в ML
author: michail_artemiev, stanislav_fedotov
---

- Этот список будет заменен оглавлением, за вычетом заголовка "Contents",
  к которому добавлен класс `no_toc`.
  {:toc}

В этой главе мы посмотрим на, казалось бы, те же самые модели машинного обучения с другой стороны, проинтерпретировав их, как вероятностные. В первом разделе мы расскажем, как обращаться с вероятностными моделями, и покажем, что привычный вам подбор параметров модели с помощью минимизации функции потерь соответствует их подбору методом максимального правдоподобия, что даст возможность транслировать в мир ML известные результаты о свойствах оценок максимального правдоподобия, но в то же время и обнажит их недостатки. Это позволит нам по-новому взглянуть на логистическую регрессию и с новым пониманием сформулировать её обобщение – generalized linear model (GLM). По ходу дела выяснится, что большинство классификаторов, хоть и делают вид, что предсказывают корректные вероятности, на самом деле вводят в заблуждение, и в третьем разделе мы поговорим о том, как проверить отклонение предсказанных значений от истинных вероятностей и как поправить ситуацию. Далее, мы обсудим генеративный подход к классификации и разберём несколько примеров генеративных моделей, после чего перейдём к байесовскому подходу оценивания параметров, который, хоть зачастую и трудно осуществим вычислительно, однако обладает большей теоретической стройностью, позволяет оценивать распределение параметров и предсказаний – то есть, например, уверенность в нашей оценке – а, кроме того, дает нам возможность измерить качество модели, не прибегая к проверке на тестовой выборке.

# Дискриминативные вероятностные модели

## Случайность как источник несовершенства модели

Практически любая модель, которую мы строим, несовершенна. Но объяснять это несовершенство можно по-разному. Рассмотрим, например, модель линейной регрессии $$y\simeq Xw$$. Можно говорить, что

- Зависимость не точная из-за того, что мы не угадали её истинную форму (она была квадратичной, кусочно линейной, с логарифмами, ещё какой-то..), но уж мы постараемся приблизить чем есть.

- Зависимость не точная из-за погрешности – а именно, из-за того, что $$y$$ искажён случайным шумом.

В первом случае мы получаем простой инженерный подход к машинному обучению: есть формула, в которой присутствуют некоторые параметры ($$w$$), есть формализация того, что такое <<приблизить>> (функция потерь) – и мы бодро решаем задачу оптимизации по параметрам.

Во втором наша логика выглядит немного по-другому. Мы заменяем приближённое равенство $$y\simeq Xw$$ на точное

$$y = \left(Xw, \mbox{искажённое шумом $\varepsilon$}\right)$$

Например, это может быть аддитивный шум (чаще всего так и делают):

$$y = Xw + \varepsilon$$

где $$\varepsilon$$ – некоторая случайная величина, которая представляет этот самый случайный шум. Тогда получается, что для каждого конкретного объекта $$x_i$$ соответствующий ему истинный таргет – это сумма $$(x_i, w)$$ и конкретной реализации шума $$\varepsilon$$.

Теперь, однако же, наша модель приобретает ещё одну степень свободы: мы можем выбирать различные распределения шума, кодируя тем самым, какой может быть ошибка. Чаще всего выбирают гауссовский шум: $$\varepsilon\sim\mathcal{N}(0,\sigma^2)$$ с некоторой дисперсией $$\sigma^2$$ – но могут быть и другие варианты. Дальше в этой главе мы увидим, что разные гипотезы о распределении этого шума соответствуют на самом деле выбору различных функций потерь. Да и вообще окажется, что эти два подхода – инженерный и вероятностный – не только не противоречат друг другу, а глубинным образом связаны.

## Условное распределение на таргет, непрерывный случай

Допустим, что мы исследуем вероятностную модель таргета с аддитивным шумом

$$y = f_w(X) + \varepsilon,$$

где $$f_w$$ – некоторая функция с (неизвестными пока) параметрами $$w$$, а $$\varepsilon$$ – случайный шум с плотностью распределения $$\varepsilon\sim p_{\varepsilon}(t)$$. Для каждого конкретного объекта $$x_i$$ значение $$f_w(x_i)$$ является просто константой, но $$y_i$$ превращается в случайную величину, зависящую от $$x_i$$ (и ещё от $$w$$ на самом деле). Таким образом, можно говорить об условном распределении

$$p_y(y \vert x, w)$$

Для каждого конкретного $$x_i$$ и $$w$$ распределение соответствующего $$y_i$$ – это просто $$p_{\varepsilon}(y - f_{w}(x_i))$$, ведь $$y - f_w(X) = \varepsilon$$.

## Вероятностные модели произвольного вида

На самом деле, мы можем для нашей задачи придумывать любую вероятностную модель $$p_y(y \vert x, w)$$, не обязательно вида $$y = f_w(X) + \varepsilon$$.

Представьте, что мы хотим предсказывать точку в плоскости штанг, в которую попадает мячом бьющий по воротам футболист. Можно предположить, что она имеет нормальное распределение со средним (цель удара), которое определяется ситуацией на поле и состянием игрока, и некоторой дисперсией (т.е. скалярной ковариационной матрицей), которая тоже зависит от состояния игрока и ещё разных сложных факторов, которые мы объявим случайными. Состояние игрока – это сложное понятие, но, вероятно, мы можем выразить его, зная пульс, давление и другие физические показатели. В свою очередь, ситуацию на поле можно описать, как функцию от позиций и движений других игроков, судьи и зрителей – но всего не перечислишь, поэтому нам снова придётся привлекать случайность. Таким образом, мы получаем то, что называется **графической моделью**:

![](images/football1.png){: .center}

Здесь стрелки означают статистические зависимости, а отсутствие стрелок – допущение о статистической независимости. Конечно же, это лишь допущение, принятое нами для ограничения сложности модели: ведь пульс человека и давление взаимосвязаны, равно как и поведение различных игроков на поле. Но мы уже обсуждали, что каждая модель, в том числе и вероятностная, является лишь приблизительным отражением бесконечно сложного мира. Впрочем, если у нас много вычислительных ресурсов, то никто не мешает нам попробовать учесть и все пропущенные сейчас зависимости.

Расписав всё по определению условной вероятности, мы получаем следующую вероятностную модель:

![](images/football2.png){: .center}

в которой, конечно же, мы должны все вероятности расписать через какие-то понятные и логически обоснованные распределения – но пока воздержимся от этого.

## Предсказание в вероятностных моделях

О том, как подбираются параметры модели, мы расскажем ниже в соответствующем разделе, а пока представим, что параметры подобраны, и подумаем о том, как же теперь делать предсказания.

Рассмотрим модель линейной регрессии

$$y = Xw + \varepsilon,\quad\varepsilon\sim\mathcal{N}(0,\sigma^2)$$

Если $w$ известен, то для нового объекта $x_0$ соответствующий таргет имеет вид

$$y_0 = x_0w + \varepsilon\sim\mathcal{N}(x_0w, \sigma^2)$$

Таким образом, $y_0$ дан нам не точно, а в виде распределения (и логично: ведь мы оговорились выше, что ответы у нас искажены погрешностью, проинтерпретированной, как нормальный шум). Но что делать, если требуют назвать конкретное число? Наверное, имеет смысл дать моду распределения (точку с максимальным значением плотности распределения), которая в данном случае будет равна $\mathbb{E}(y_0\vert x_0, w)$, но на самом деле может и отличаться от условного матожидания, если будет выбрана какая-то другая модель шума.

Аналогичные соображения можно применять и для более сложных моделей, выдавая предсказание в виде моды условного распределения, то есть $$\underset{y_0}{\operatorname{argmax}}\log{p(y_0\vert x_0, w)}$$, или условного математического ожидания $$\mathbb{E}(y_0\vert x_0, w)$$, или условной медианы, или ещё чего-то такого, что вам кажется правильным.

## Условное распределение на таргет, дискретный случай

Допустим, мы имеем дело с задачей классификации с $$K$$ классами. Как мы можем её решать? Самый наивный вариант – научиться по каждому объекту $$x_i$$ предсказывать некоторый некоторое число для каждого класса, и у кого число больше – тот класс и выбираем! Наверное, так можно сделать, если мы придумаем хорошую функцию потерь. Но сразу в голову приходит мысль: почему бы не начать предсказывать не просто число, а вероятность?

Таким образом, задача классификации сводится к предсказанию

$$P(y_i = k \vert x_i)$$

и как будто бы выбору класса с наибольшей вероятностью (как мы увидим дальше, всё не всегда работает так просто).

Одну такую модель – правда, только для бинарной классификации – вы уже знаете. Это логистическая регрессия:

$$P(y_i = 1 \vert x_i,w) = \frac{1}{1+e^{-\langle x_i, w\rangle}},\quad P(y_i = 0 \vert x_i,w) = \frac{e^{-(x_i, w)}}{1+e^{-\langle x_i, w\rangle}} = \frac{1}{1+e^{\langle x_i, w\rangle}}$$

которую также можно записать в виде

$$y_i \vert x_i \sim \color{red}{Bern}\left(\frac{1}{1+e^{\langle x_i, w\rangle}}\right)$$
где $\color{red}{Bern}(p)$ – распределение Бернулли с параметром $p$.

Отметим, что, если забыть, как мы пришли к модели логистической регрессии, оказывается, что это просто

$$
x_i\xrightarrow{\begin{smallmatrix}\mbox{Какое-то}\\\mbox{отображение}\end{smallmatrix}}
\left(-\langle x_i, w\rangle, \langle x_i, w\rangle\right)\xrightarrow{\ \sigma\ }\left(\sigma(-\langle x_i, w\rangle),
\sigma(\langle x_i, w\rangle)\right)
$$

где, напомним, $$\sigma$$ – это сигмоида:

$$\sigma(t) = \frac{1}{1+e^{-t}}$$

Сигмоида тут не просто так. Она обладает теми счастливыми свойствами, что

- монотонно возрастает;

- отображает всю числовую прямую на интервал $$(0,1)$$;

- $$\sigma(-x) = 1 - \sigma(x)$$.

Вот такой вид имеет её график:

![](images/sigmoid.png){: .center style="width:30vw"}

Иными словами, с помощью сигмоиды можно делать ''вероятности'' из чего угодно, то есть более или менее для любого отображения $$f_w$$ (из признакового пространства в $$\mathbb{R}$$) с параметрами $$w$$ построить модель бинарной классификации

$$P(y_i = 0 \vert x_i, w) = \sigma(f_w(-x_i)),\quad P(y_i = 1 \vert x_i, w) = \sigma(f_w(x_i))$$

Как и в случае логистической регрессии, такая модель равносильна утверждению о том, что

$$f_w(x_i) = \log{\frac{p(y = 1 \vert x_i,w)}{p(y = 0 \vert x_i, w)}}$$

Похожим способом можно строить и модели для многоклассовой классификации; в этом нам поможет обобщение сигмоиды, которое называется **softmax**:

$$softmax(t_1,\ldots,t_K) = \left(\frac{e^{t_1}}{\sum_{k=1}^Ke^{t_k}},\ldots,\frac{e^{t_K}}{\sum_{k=1}^Ke^{t_k}}\right)$$

А именно, для любого отображения $$f_w$$ из пространства признаков в $$\mathbb{R}^K$$ мы можем взять модель

$$\left(P(y_i = k \vert x_i, w)\right)^K_{k=1} = softmax(f_w(x_i))$$

Если все наши признаки – вещественные числа, а $$f_w(x_i) = x_iW$$ – просто линейное отображение, то мы получаем однослойную нейронную сеть

$$\left(P(y_i = k \vert x_i, w)\right)^K_{k=1} = softmax(x_iW)$$

![](images/prob-ML-1NN.png){: .center style="width:40vw"}

**Предостережение**. Всё то, что мы описали выше, вполне работает на практике (собственно, классификационные нейросети зачастую так и устроены), но корректным не является. В самом деле, мы говорим, что строим оценки вероятностей $$P(y_i = k \vert x_i, w)$$, но для подбора параметров используем не эмпирические вероятности, а только лишь значения $$\underset{k}{\operatorname{argmax}} \ P(y_i = k \vert x_i, w)$$, то есть метки предсказываемых классов. Таким образом, мы не сможем различить ситуации

![](images/prob-ML-uncertain.png){: .center}

Это говорит нам о некоторой неполноценности такого подхода.

Заметим ещё вот что. В случае бинарной классификации выбор предсказываемого класса как $$\underset{k}{\operatorname{argmax}} P(y_i=k \vert x_i,w)$$ равносилен выбору того класса, для которого $$P(y_i=k \vert x_i,w) > \frac{1}{2}$$. Но если наши оценки вероятностей неадекватны, то этот вариант проваливается, и мы встаём перед проблемой выбора порога: каким должно быть значение $$\widehat{t}$$, чтобы мы могли приписать класс 1 тем объектам $$x_i$$, для которых $$\sigma(f_w(x_i)) > \widehat{t}$$?

В одном из следующих разделов текущей главы мы обсудим, как всё-таки правильно предсказывать вероятности.

# Обобщенные линейные модели

В этом разделе мы рассмотрим достаточно широкий класс моделей – обобщённые линейные модели (generalized linear models, GLM). К ним относятся, в частности, линейная и логистическая регрессии. В итоге мы научимся подбирать подходящую регрессионную модель для самых разных типов данных.
Вероятностную модель линейной регрессии можно записать как $Y \vert X \sim\color{red}{\mathcal N}(Xw, \sigma^2)$, а вероятностную модель логистической регрессии – как $Y \vert X \sim \color{red}{Bern}(\color{blue}{sigmoid}(Xw))$ (где $\color{red}{Bern}(p)$ – распределение Бернулли с параметром $p$, а $\color{blue}{sigmoid}(u) = \frac{1}{1+e^{-u}}$).

Итак, чем в этих терминах отличаются вероятностные модели линейной и логистической регрессии?

1. Параметризованное семейство распределений для $Y \vert X$, а именно, $\color{red}{\mathcal N}(\*, \sigma^2)$ в случае линейной регрессии и $\color{red}{Bern}$ в случае логистической.

2. Для каждой из задач мы выбрали функцию $g$ такую, что $g(\mathbb E(Y \vert X)) = Xw$. Эта функция называется _функцией связи (link function)_. В случае линейной регрессии $g(u) = u$. В случае логистической регрессии $$g(u) = \text{sigmoid}^{-1}(u) = \text{logit}(u) = \log\frac{u}{1-u}$$.

Обобщая, можно сказать, что, если данные таковы, что $\mathbb E(Y \vert X)$ не является линейной функцией от $x$, мы линеаризуем $\mathbb E(Y \vert X)$ с помощью функции связи $g$.

**Замечание:** Вообще говоря, нормальное распределение определяется не только своим мат. ожиданием, но и стандартным отклонением. То есть, в отличие от логистической регрессии, обученная модель линейной регрессии не позволяет для данного $x$ оценить распределение $y \vert x$. К счастью, выбор значения $\sigma$ в нормальном распределении не влияет ни на оптимальный вектор весов $w$, ни на итоговые предсказания $\mathbb E(Y \vert X)$, которые выдаёт обученная модель.

Задав эти две составляющие, мы получим GLM. Для нового объекта $x$ она выдаст предсказание $g^{-1}(xw)$, а выбор класса $Y \vert X$ потребуется нам для подбора весов $w$. В принципе, можно выбрать любой класс распределений $Y \vert X$ и монотонную функцию связи $g$, получив некоторую вероятностную модель. Однако обычно для упрощения поиска оптимальных весов $w$ в GLM предполагают, что $Y \vert X$ принадлежит **экспоненциальному семейству распределений**.

Семейство распределений называют экспоненциальным (или семейством из экспоненциального класса), если все принадлежащие ему распределения могут быть записаны в виде:

$$p(y \vert \theta, \phi) = \exp\left(\frac{y\theta - a(\theta)}{\phi} + b(y, \phi)\right)$$

где $\theta, \phi$ – вещественнозначные параметры, а $a, b$ – произвольные функции, которые считаются известными (лишь бы итоговая функция в самом деле была вероятностной мерой, то есть суммировалась или интегрировалась в единицу). Число $\phi$ называют "scale parameter", так как оно отвечает за разброс распределения.

Нетрудно показать, что математическое ожидание распределения из экспоненциального семейства равно $\mu = a'(\theta)$.

<details>
  <summary markdown="span">Доказательство</summary>
  Заметим, что

$$\exp\left(\frac{y\theta - a(\theta)}{\phi} + b(y, \phi)\right) = \frac{\exp\left(\frac{y\theta}{\phi} + b(y, \phi)\right)}{\exp\left(\frac{a(\theta)}{\phi}\right)},$$

откуда

$$\exp\left(\frac{a(\theta)}{\phi}\right) = \int\exp\left(\frac{y\theta}{\phi} + b(y, \phi)\right)dy$$

Следовательно,

$$a(\theta) = \phi\log\int\exp\left(\frac{y\theta}{\phi} + b(y, \phi)\right)dy$$

Дифференцируя, получаем

$$a'(\theta) = \frac{\phi}{\int\exp\left(\frac{y\theta}{\phi} + b(y, \phi)\right)dy}\cdot\int\frac{\partial}{\partial\theta}\,\exp\left(\frac{y\theta}{\phi} + b(y, \phi)\right)dy=$$

$$=\frac{\phi}{\exp\left(\frac{a(\theta)}{\phi}\right)}\int \frac{y}{\phi}\cdot\exp\left(\frac{y\theta}{\phi} + b(y, \phi)\right)dy=\int{p(y\vert\theta,\phi)y dy} = \mathbb{E}p(y\vert\theta,\phi)$$

что и завершает доказательство.

</details>

В модели GLM мы предполагаем, что $g(\mu) = Xw$, т.е. $\mu = g^{-1}(Xw) = a'(\theta)$. Если дополнительно положить $\theta = Xw$, то мы сможем однозначно определить функцию связи $g = (a')^{-1}$. Такая функция связи называется **канонической (canonical link function)**.

Даже если мы решили использовать каноническую функцию связи, т.е. положили $\theta = Xw$, непонятно, как на практике подбирать $\phi, a, b$, чтобы по классу распределений $Y \vert X$ определить каноническую функцию связи. Чтобы разобраться, рассмотрим несколько примеров.

**Пример 1** Пусть мы решили применить к данным линейную регрессию. Тогда

$$p(y \vert \mu, \sigma^2) = \frac{1}{\sqrt{2\pi}\sigma}\exp\left(-\frac{(y-\mu)^2}{2\sigma^2}\right)$$

Чтобы увидеть в этой формуле плотности экспоненциальное семейство распределений, занесём всё внутрь экспоненты:

$$p(y \vert \mu, \sigma^2) = \exp\left(-\frac{(y-\mu)^2 }{2\sigma^2}- \log(2\pi\sigma^2)\right)$$

В формуле экспоненциального семейства распределений единственная часть, не зависящая от $\theta$ - функция $b$. Поскольку $\mu=a'(\theta)$, функция $b$ также не должна зависеть от $\mu$. Так что внутри экспоненты выделим в качестве функции $b$ всё, что не зависит от $\mu$:

$$p(y \vert \mu, \sigma^2) = \exp\left(\frac{y\mu - \mu^2/2}{\sigma^2} - \left(\frac{y^2}{2\sigma^2} + \log(2\pi\sigma^2)\right)\right)$$

Эта формула уже похожа на формулу экспоненциального семейства распределений и видно, что $\phi=\sigma^2$, $\theta=g(\mu)=\mu$ (коэффициент при $y$), $a(\theta) = \mu^2/2 = \theta^2/2$, $b(y, \phi) = -\frac{y^2}{2\sigma^2} - \log(2\pi\sigma^2)$

**Пример 2** Проделаем то же самое, но теперь для распределения Бернулли. Имеем функцию массы

$$p(y \vert \mu) = \mu^y(1-\mu)^{1-y} = \exp\left(y\log\left(\frac{\mu}{1-\mu}\right) + \log\left(1-\mu\right)\right)$$

Т.е. $\phi=1$, $\theta = g(\mu) = \log\frac{\mu}{1-\mu}$ (как и ожидалось, получили функцию связи $\text{logit}$, используемую в логистической регрессии), $a(\theta) = -\log\left(1-\mu\right) = \log\left(1 + \exp(\theta)\right)$, $b=0$.

**Пример 3** Хорошо, про линейную и логистическую регрессию мы и так знали. Давайте попробуем решить с помощью GLM новую задачу. Пусть мы хотим по каким-то признакам $X$ предсказать количество "лайков", которое пользователи поставят посту в социальной сети за первые 10 минут после публикации. Конечно, можно использовать для этого линейную регрессию. Однако предположение линейной регрессии, что $Y \vert X\sim\mathcal N$, в данном случае странное по нескольким причинам. Во-первых, количество лайков заведомо не может быть отрицательным, а нормальное распределение всегда будет допускать ненулевую вероятность отрицательного значения. Во-вторых, количество лайков – всегда целое число. В-третьих, у распределения количества лайков, скорее всего, положительный коэффициент асимметрии (skewness). То есть, если модель предсказывает, что под постом будет 100 лайков, мы скорее можем ожидать, что под ним окажется 200 лайков, чем 0. Нормальное распределение симметрично и не может описать такие данные. С другой стороны, если мы предположим, что в первые 10 минут после публикации есть какая-то постоянная частота (своя для каждого поста, зависящая от $x$), с которой пользователи ставят лайк, мы получим, что количество лайков имеет распределение Пуассона. Распределение Пуассона не имеет описанных выше проблем:

![](images/Poisson_vs_Gaussian.png){: .center style="width:40vw"}

Но какая будет каноническая функция связи, если мы считаем, что $Y \vert X\sim\text{Poisson}$? Аналогично примерам 1, 2:

$$p(y \vert \mu) = \frac{e^{-\mu}\mu^y}{y!} = \exp\left(y\log\mu - \mu - \log y!\right)$$

Откуда $\phi=1$, $\theta = g(\mu) = \log\mu$, $a(\theta) = \mu = \exp(\theta)$, $b(y, \phi) = -\log y!$

Значит, эта модель, называемая Пуассоновской регрессией, будет предсказывать с помощью формулы $\mathbb E(y \vert x) = g^{-1}(x^Tw)= \exp(x^Tw)$.

Как мы увидели, к экспоненциальным семействам относятся как непрерывные, так и дискретные распределения. Вообще, к ним относится большая часть распределений, которыми Вам на практике может захотеться описать $Y \vert X$. В том числе,

- нормальное
- распределение Пуассона
- экспоненциальное
- биномиальное, мультиномиальное (с фиксированным числом испытаний)
- геометрическое
- $\chi^2$-распределение
- бета-распределение
- гамма-распределение
- распределение Дирихле

К экспоненциальным семействам не относятся: равномерное распределение на отрезке, $t$-распределение Стьюдента, распределение Коши, смесь нормальных распределений.

Теперь, когда мы разобрались, как по задаче построить вероятностную модель GLM, встаёт вопрос, как учить такую модель, т.е. как подбирать веса $w$. Подбору параметров вероятностной модели посвящён следующий раздел. Когда будете его читать, обратите внимание, что в функцию потерь войдёт логарифм плотности (или функции массы) $y \vert x, w$. Логарифмировать плотность распределений из экспоненциальных семейств одно удовольствие: достаточно убрать экспоненту, так что оптимизационная задача в итоге получится простая. Это одна из причин, почему в GLM используются именно экспоненциальные семейства распределений.

# Подбор параметров вероятностной модели

## Оценка максимального правдоподобия и оптимизация функции потерь

Мы хотим подобрать такие значения параметров $$w$$, для которых модель $$p_y(y \vert x, w)$$ была бы наиболее адекватна обучающим данным. Суть **метода максимального правдоподобия** (**maximum likelihood estimation**) состоит в том, чтобы найти такое $$w$$, для которого вероятность (а в данном, непрерывном, случае плотность вероятности) появления выборки $$\{y_1, \ldots, y_N\}$$ была бы максимальной, то есть

$$\widehat{w}_{MLE} = \underset{w}{\operatorname{argmax}}p(y \vert X, w)$$

Величина $$p(y \vert X, w)$$ называется **функцией правдоподобия** (**likelihood**). Если мы считаем, что все объекты независимы, то функция правдоподобия распадается в произведение:

$$p(y \vert X, w) = p(y_1 \vert x_1, w) \cdot\ldots\cdot p(y_i \vert x_i, w)$$

Теперь, поскольку перемножать сложно, а складывать легко (и ещё поскольку мы надеемся, что, раз наши объекты всё-таки наблюдаются в природе, их правдоподобие отлично от нуля), мы переходим к логарифму функции правдоподобия:

$$l(y \vert X,w) = \log{p(y_1 \vert x_1, w)} + \ldots + \log{p(y_i \vert x_i, w)}$$

эту функцию мы так или иначе максимизируем по $$w$$, находя оценку максимального правдоподобия $$\hat{w}$$.

В прошлой главе мы видели, что оценка максимального правдоподобия для регрессионной модели $$y\sim Xw+\varepsilon$$, где $$\varepsilon\sim\mathcal{N}(0, \sigma^2)$$ совпадает с решением задачи линейной регрессии с квадратичной функцией потерь. В общем случае это тоже верно: ведь
$$l(y \vert X,w) = \sum\limits_{i=1}^N\log{p_{\varepsilon}(y_i - f_w(x_i))}$$
что является некоторой функцией потерь, которую можно оптимизировать совершенно в духе инженерного подхода.

## Состоятельность оценки максимального правдоподобия

Понятно, что, имея на руках лишь несколько обучающих примеров, мы не сможем удовлетворительно оценить истинное значение $$w^{\ast}$$ параметра $$w$$. Тем не менее, хочется надеяться, что при больших $$N$$ наша оценка будет близка к точной.

В теории вероятностей это свойство известно под названием **состоятельность оценки**. А именно, оценка называется **состоятельной**, если при $$n\rightarrow\infty$$ оценка $$\widehat{w}_{MLE}$$ стремится к $$w^{\ast}$$ по вероятности.

Поясним, что тут имеется в виду. Вообще говоря, мы не имеем дело со всем универсумом возможных данных $$\mathbb{X}$$, и нам доступна лишь конечная обучающая выборка $$X$$, которую можно считать случайно выбранным подмножеством. И смысл сходимости по вероятности следующий: для любого заранее выбранного $$\delta$$ с ростом $$N$$ вероятность получить на руки такую неудачную выборку $$X$$, для которой $$\vert \widehat{w}_{MLE} - w^{\ast}\vert > \delta$$, стремится к нулю.

Так вот, оценка максимального правдоподобия является состоятельной. Давайте попробуем не то чтобы доказать, но понять, почему так происходит.

$$l(y \vert X,w) \xrightarrow{N\rightarrow\infty} \sum_{y_{\ast}}\log{p(y_{\ast} \vert x_{\ast}, w)} = \mathbb{E}_{y_{\ast}\sim p(y_{\ast} \vert x_{\ast},w^{\ast})}\log{p(y_{\ast} \vert x_{\ast}, w)} = $$

$$ = \mathbb{E}_{y_{\ast}\sim p(y*{\ast} \vert x*{\ast},w^{\ast})}\log\left(\frac{p(y*{\ast} \vert x*{\ast},w)}{p(y*{\ast} \vert x*{\ast},w^{\ast})}\cdot p(y*{\ast} \vert x*{\ast}, w^{\ast})\right) =$$

$$= - KL\left(p(y_{\ast} \vert x_{\ast},w^{\ast}) \| p(y_{\ast} \vert x_{\ast}, w)\right) + \mathbb{E}_{y_{\ast}\sim p(y_{\ast} \vert x_{\ast},w^{\ast})}\log{p(y_{\ast} \vert x_{\ast},w^{\ast})} $$

Иными словами, при $$N$$, стремящемся к бесконечности, $$\widehat{w}_{MLE}$$ минимизирует расстояние Кульбака-Лейблера между $$p(y_{\ast} \vert x_{\ast},w^{\ast})$$ и $$p(y_{\ast} \vert x_{\ast},w)$$, откуда и можно сделать вывод, что $$\widehat{w}_{MLE}$$ стремится к $$w^{\ast}$$.

Тем не менее, мы всегда имеем дело с конечными $$N$$, и это значит, что $$\widehat{w}_{MLE}$$ будет отлично от $$w^{\ast}$$. А проверить, насколько мы получили адекватную оценку, мы можем, измерив правдоподобие тестовой выборки – то есть значение функции потерь на ней (это не то чтобы прекрасно обосновано теоретически, но работает).

## Преимущества вероятностного подхода

А если получилось то же самое, что и в инженерном подходе, то зачем такие сложности?

Безусловно, инженерный подход весьма могущественен и эффективен, но чем дальше, тем он больше может начать напоминать вам парад странных эвристик, осмыслить, понять и простить которые как раз и помогает вероятностная интерпретация.

Но есть и более практические приложения. Например, мы уже обсуждали, что в ''наивных'' моделях классификации вида

$$y = \underset{k}{\operatorname{argmax}}\,softmax(f_w(X))$$

мы не можем обоснованно различать ситуации, когда модель ''уверенно'' выбирает тот или иной класс и когда модель присваивает всем классам практически одинаковые вероятности, так что класс-победитель становится таковым, быть может, лишь благодаря погрешности вычислений. Использование вероятностных моделей может позволить нам корректно предсказывать не только метку класса, но и её распределение, тем самым определяя и эту неуверенность. Об этом мы поговорим в одном из следующих разделов.

**При этом данные должны быть из одного распределения!**

Один из способов выстрелить себе в ногу при работе с моделями машинного обучения – это применять их к данным не из того распределения, которое использовалось при обучении. Например, если вы обучили модель, предсказывающую спрос на товары, на данных за весну и лето, в канун Нового Года она вряд ли будет выдавать что-то адекватное: ведь все ринутся за подарками. Точно так же система машинного перевода, обученная исключительно на классической литературе, вряд ли пригодится для перевода технических инструкций. Не стоит забывать и о том, что даже самая хорошая модель будет ''протухать'' с течением времени: ведь мир вокруг меняется, и её нужно обновлять.

В дальнейшем вам предстоит познакомиться с комплексом подходов, которые позволяют адаптировать модель к новым условиям (например, научить распознающую лица нейросеть распознавать ещё и эмоции) – эта область машинного обучения называется **transfer learning** (**перенос обучения**).

## Асимптотическая нормальность и компромисс между качеством и сложностью модели

Ещё одним известным свойством оценки максимального правдоподобия является **асимптотическая нормальность**. Если оценивать наши веса $$w$$ по различным наборам из $$N$$ обучающих примеров, причём считать, что наборы выбираются случайно (не будем уточнять, как именно), то оценка $$\widehat{w}_{MLE}$$ тоже превращается в случайную величину, которая как-то распределена. Теория утверждает, что при $N\rightarrow\infty$

$$ \quad \widehat{w}\_{MLE}\sim\mathcal{N}\left(w^{\ast}, I_N({w}^{\ast})^{-1}\right)$$

где $$w^{\ast}$$ – истинное значение весов, а $$I_N({w}^{\ast})$$ – матрица информации Фишера, которая определяется как

$$I_N({w}^{\ast}) = \mathbb{E}\left[\left(\left.\frac{\partial}{\partial w_i}\log{p(y \vert X,w)}\right|_{w^{\ast}}\right)\left(\left.\frac{\partial}{\partial w_j}\log{p(y \vert X,w)}\right|_{w^{\ast}}\right)\right]$$

что при некоторых не слишком обременительных ограничениях равно

$$I_N({w}^{\ast}) = -\mathbb{E}\left[\left.\frac{\partial^2}{\partial w_i\partial w_j}\log{p(y \vert X,w)}\right|_{w^{\ast}}\right]$$

При этом поскольку $$\log{p(y \vert X,w)} = \sum_{i=1}^N\log{p(y_i \vert x_i, w)}$$, матрица тоже распадается в сумму, и получается, что $$I_N({w}^{\ast}) = NI_1(w^{\ast})$$, то есть с ростом $$N$$ ковариация $$(NI_1(w^{\ast}))^{-1}$$ оценки максимального правдоподобия стремится к нулю.

На интуитивном уровне можно сказать, что матрица информации Фишера показывает, сколько информации о весах $$w$$ содержится в $$X$$.

Заметим, что в реальной ситуации мы не знаем $$w^{\ast}$$ и тем более не можем посчитать матрицу Фишера. Это одна из проблем с оценками максимального правдоподобия (в сравнении с апостериорными байесовскими оценками, о которых пойдёт речь в третьем разделе): всякие теоретические штуки невозможно честно вычислить на практике, и приходится заменять их оценками. Ясно, что вместо $$w^{\ast}$$ можно взять просто $$\widehat{w}$$, а вместо $$I_N(w^{\ast})$$ – матрицу $$I_N(\widehat{w})$$, которую можно даже при желании определить как

$$-\left(\left.\frac{\partial^2}{\partial w_i\partial w_j}\log(p(y \vert X, w))\right|_{w^{\ast}}\right)$$

безо всякого математического ожидания.

Эти инструменты позволяют построить доверительный интервал для оцениваемых параметров, но следует помнить, что по ходу нами было сделано много упрощений: мы предположили, что асимптотическая оценка распределения уже достигнута, от $$w^{\ast}$$ перешли к $$\widehat{w}$$, а для полноты чувств ещё и избавились от математического ожидания.

### Сложность модели и количество данных

Попробуем очень нестрого понять, как влияет число весов на скорость сходимости модели. Асимптотически $$\widehat{w}_{MLE}\sim\mathcal{N}\left(w^{\ast}, (NI_1({w}^{\ast}))^{-1}\right)$$, то есть стандартное отклонение каждого из $$\widehat{w}_{j}$$ убывает примерно как $$\frac{1}{\sqrt{N}}$$. В свою очередь, $$\|\widehat{w} - w^{\ast}\|$$ будет с хорошей вероятностью ограничено чем-то в духе $$\frac{D}{\sqrt{N}}$$. То есть, условно говоря, если мы увеличиваем число параметров в $$m$$ раз и не просесть по качеству, то мы должны быть готовы взять в $$m^2$$ больше данных. Повторимся, это совсем нестрогие рассуждения, но они помогают понять, почему взлёт нейронных сетей начался, лишь когда стали появляться очень большие датасеты (ну, и сильная вычислительная техника, конечно).

**Пример**. Рассмотрим модель линейной регрессии $$y\sim Xw + \varepsilon$$, $$\varepsilon\sim\mathcal{N}(0, \sigma^2)$$. Для неё

$$\log{p(y \vert X,w)} = -\frac{N}{2\log(2\pi\sigma^2)} - \frac{1}{2\sigma^2}(y - Xw)^T(y - Xw)$$

Нетрудно убедиться, что

$$\nabla_w\log{p(y \vert X,w)} = \frac{1}{\sigma^2}X^T(y - Xw)$$

$$\nabla^2_w\log{p(y \vert X,w)} = -\frac{1}{\sigma^2}X^TX$$

Соответственно,

$$I_N(\widehat{w}) = \frac{1}{\sigma^2}X^TX$$

где $$\widehat{w}$$ – это полученная по датасету $$X$$ оценка весов. Заметим, что $$X^TX$$ – это с точностью до коэффициента $$\frac{1}{N}$$ оценка ковариационной матрицы признаков нашего датасета (элементы $$X^TX$$ – это скалярные произведения столбцов $$X$$, то есть столбцов признаков). Можно легко убедиться, что

$$\frac{1}{\sigma^2}X^TX = \frac{1}{\sigma^2}\sum_{i=1}^Nx_i^Tx_i$$

По-хорошему, нам надо было бы ещё взять математическое ожидание. Найти его мы не можем, но можем очень наивно оценить как $$C = \frac1N\sum_{i=1}^Nx_i^Tx_i$$. Тогда получаем, что $$I_N(\widehat{w}) = \frac{N}{\sigma^2}C$$. Таким образом, имея один датасет $$X$$ и одну посчитанную по нему оценку $$\widehat{w}$$, мы можем довольно грубо оценить распределение оценок максимального правдоподобия для заданного $$N$$ как

$$\mathcal{N}\left(\widehat{w}, \frac{N}{\sigma^2}C\right)$$

**Пример в примере**. Давайте рассмотрим задачу аппроксимации функции одной переменной (чьи значения в обучающей выборке искажены нормальным шумом) многочленом степени не выше $$3$$. Положим в вероятностной модели $$\sigma^2 = 1$$. Тогда различный выбор обучающих датасетов будет приводить к различным результатам:

![](images/prob-ML-freq-regression1.png){: .center style="width:37vw"}

Но разброс результатов падает с ростом $$N$$.

**Ещё пример в примере**. Рассмотрим ещё одну задачу регрессии с двумя признаками (в которой всё так же будем полагать $$\sigma^2 = 1$$), для которой оценим распределение $$w_0$$ через первую компоненту $$\mathcal{N}(\widehat{w}, I_N(\widehat{w})^{-1})$$ для одного конкретного $$\widehat{w}$$ и нарисуем несколько различных $$\widehat{w}$$, полученных из других датасетов той же мощности:

![](images/prob-ML-freq-regression2.png){: .center style="width:37vw"}

Видим, что средние оцененного распределения сходятся к истинному значению $$-1$$; при этом дисперсия падает. Красные крестики не вполне подчиняются синему распределению, но мы от них ждём лишь приближённой согласованности, которая имеет место.

# Оценка вероятностей

Мы уже упоминали, что оценивать вероятности классов как $$softmax(f_w(x_i))$$ для какой-то произвольной функции $$f_w$$ – это дело подозрительное. В этом разделе мы поговорим о том, как это делать хорошо и правильно.

## Что такое вероятность класса?

Ограничимся пока случаем двуклассовой классификации с классами 0 и 1. Пожалуй, если утверждается, что мы предсказываем корректную вероятность класса 1 (обозначим её $$q(x_i)$$), то прогноз <<объект $$x_i$$ принадлежит классу 1 с вероятностью $$\frac23$$>> должен сбываться в $$\frac23$$ случаев. То есть, условно говоря, если мы возьмём все объекты, которым мы предсказали вероятностью $$\frac23$$, то среди них что-то около двух третей действительно имеет класс 1. На математическом языке это можно сформулировать так: **Если $$\widehat{p}$$ – предсказанная вероятность класса 1, то $$P(y_i = 1 \vert q(x_i) = \widehat{p}) = \widehat{p}$$**.

К сожалению, в реальной жизни $$\widehat{p}$$ – это скорее всего вещественные числа, которые будут различными для различных $$y_i$$, и никаких вероятностей мы не посчитаем, но мы можем разбить отрезок $$[0,1]$$ на бины, внутри каждого из которых уже вычислить, каковая там доля объектов класса 1, и сравнить эту долю со средним значением вероятности в бине:

![](images/prob-ML-calibration.png){: .center}

У модели, которая идеально предсказывает вероятности (как обычно говорят, у идеально <span style="color:blue">калиброванной</span> модели) красные точки на диаграме калибровки должны совпадать с синими.

А вот на картинке выше это не так: красные точки всегда ниже синих. Давайте поймём, что это значит. Получается, что наша модель систематически завышает предсказанную вероятность (синие точки), и порог отсечения нам, выходит, тоже надо было бы сдвинуть вправо:

![](images/prob-ML-calibration1.png){: .center}

Но такая картинка, пожалуй, говорит о какой-то серьёзной патологии классификатора; гораздо чаще встречаются следующие две ситуации:

- Слишком уверенный (**overconfident**) классификатор:
  ![](images/prob-ML-calibration2.png){: .center}
  Такое случается с сильными классификаторыми (например, нейросетями), которые учились на метки классов, а не на вероятности: тем самым процесс обучения стимулировал их всегда давать как можно более близкий к 0 или 1 ответ.

- Неуверенный (**underconfident**) классификатор:
  ![](images/prob-ML-calibration3.png){: .center}

Такое может случиться, например, если мы слишком много обращаем внимания на трудные для классификации объекты на границе классов (как, скажем, в SVM), в каком-то смысле в ущерб более однозначно определяемым точкам. Этим же могут и грешить модели на основе бэггинга (например, случайный лес). Грубо говоря, среднее нескольких моделей предскажет что-то близкое к единице только если все слагаемые предскажут что-то, близкое к единице – но из-за дисперсии моделей это будет случаться реже, чем могло бы. См. [статью](https://www.cs.cornell.edu/~alexn/papers/calibration.icml05.crc.rev3.pdf).

## Предсказание вероятностей с помощью логистической регрессии

Вам скажут: логистическая регрессия корректно действительно предсказывает вероятности.

Вам даже будут приводить какие-то обоснования. Важно понимать, что происходит на самом деле, и не дать ввести себя в заблуждение. В качестве противоядия от иллюзий предлагаем рассмотреть два примера.

- Рассмотрим датасет c двумя классами (ниже на картинке обучающая выборка)

![](images/prob-ML-logreg-calib0.png){: .center style="width:30vw"}

Обучим на нём логистическую регрессию из sklearn безо всяких параметров (то есть $$L^2$$-регуляризованную, но это не так важно). Классы не так-то просто разделить, вот и логистическая регрессия так себе справляется. Ниже изображена часть тестовой выборки вместе с предсказанными вероятностями классов для всех точек области

![](images/prob-ML-logreg-calib1.png){: .center style="width:30vw"}

Видим, что модель не больно-то уверена в себе, и ясно почему: признаковое описание достаточно бедное и не позволяет нам хорошо разделить классы, хотя, казалось бы, это можно довольно неплохо сделать.

- Попробуем поправить дело, добавив полиномиальные фичи, то есть все $$x^jy^k$$ для $$0\leqslant j,k\leqslant 5$$ в качестве признаков, и обучив поверх этих данных логистическую регрессию. Снова нарисуем некоторые точки тестовой выборки и предсказания вероятностей для всех точек области:

![](images/prob-ML-logreg-calib2.png){: .center style="width:30vw"}

Видим, что имеет место сочетание двух проблем: неуверенности посередине и очень уверенных ошибок по краям.

Нарисуем теперь калибровочные кривые для обеих моделей:

![](images/prob-ML-logreg-calib3.png){: .center}

Калибровочные кривые весьма примечательны; в любом случае ясно, что с предсказанием вероятностей всё довольно плохо. Посмотрим ещё, какие вероятности наши классификаторы чаще приписывают объектам:

![](images/prob-ML-logreg-calib4.png){: .center}

Как и следовало ожидать, предсказания слабого классификатора тяготеют к серединке (та самая неуверенность), а среди предсказаний переобученного очень много крайне уверенных (и совсем не всегда правильных).

## Скалиброванность логистической регрессии

Но почему же все твердят, что логистическая регрессия хорошо калибрована?!

Попробуем понять и простить её.

Как мы помним, логистическая регрессия учится путём минимизации функционала

$$l(X, y) = -\sum_{i=1}^N(y_i\log(\sigma(\langle w, x_i\rangle)) + (1 - y_i)\log(1 - \sigma(\langle w, x_i\rangle)))$$

Отметим между делом, что каждое слагаемое – это кроссэнтропия распределения $$P$$, заданного вероятностями $$P(0) = 1 - \log(\sigma(\langle w, x_i\rangle))$$ и $$P(1) = \log(\sigma(\langle w, x_i\rangle))$$, и тривиального распределения, которое равно $$y_i$$ с вероятностью $$1$$.

Допустим, что мы обучили по всему универсуму данных $$\mathbb{X}$$ идеальную логистическую регрессию с идеальными весами $$w^{\ast}$$. Пусть, далее, оказалось, что у нас есть $$n$$ объектов $$x_1,\ldots,x_n$$ с одинаковым признаковым описанием (то есть по сути представленных одинаковыми векторами $$x_i$$), но, возможно, разными истинными метками классов $$y_1,\ldots,y_n$$. Тогда соответствующий им кусок функции потерь имеет вид

$$-\left(\sum_{i=1}^ny_i\right)\log(\sigma(\langle w, x_1\rangle)) -\left(\sum_{i=1}^n (1 - y_i)\right)\log(1 - \sigma(\langle w, x_1\rangle)) =$$

$$=-n\left(\vphantom{\frac12}p_1\log(\sigma(\langle w, x_1\rangle)) + p_0\log(1 - \sigma(\langle w, x_1\rangle))\right)$$

где $$p_j$$ – частота $$j$$-го класса среди истинных меток. В скобках также стоит кросс-энтропия распределения, задаваемого частотой меток истинных классов, и распределения, предсказываемого логистической регрессией. Максимальное значение кросс-энтропии (и минимум функции потерь) достигается, когда

$$\sigma(\langle w, x_1\rangle) = p_1,\quad 1 - \sigma(\langle w, x_1\rangle) = p_0$$

Теперь, если признаковое описание данных достаточно хорошее (то есть классы не перемешаны как попало и всё-таки близки к разделимым) и в то же время модель не переобученная (то есть, в частности, предсказания вероятностей не скачут очень уж резко – вспомните второй пример), то результат, полученный для $$n$$ совпадающих точек будет приблизительно верным и для $$n$$ достаточно близких точек: на всех них модель будет выдавать примерно долю положительных, то есть тоже хорошую оценку вероятности.

## Методы калибровки

Пусть наша модель (бинарной классификации) для каждого объекта $$x_i$$ выдаёт некоторое число $$q(x_i)\in[0,1]$$. Как же эти числа превратить в корректные вероятности?

- **Гистограммная калибровка**. Мы разбиваем отрезок $$[0,1]$$ на бины $$\mathbb{B}_1,\ldots,\mathbb{B}_k$$ (одинаковой ширины или равномощные) и хотим на каждом из них предсказывать всегда одну и ту же вероятность: $$\theta_j$$, если $$q(x_i)\in \mathbb{B}_j$$. Вероятности $$\theta_i$$ подбираются так, чтобы они как можно лучше приближали средние метки классов на соответствующих бинах; иными словами, мы решаем задачу

$$\sum_{j=1}^k\left|\frac{\sum_{i=1}^N\mathbb{I}\{q(x_i)\in\mathbb{B}_j\}}{ \vert \mathbb{B}_j \vert } - \theta_j\right|\longrightarrow\min\limits_{(\theta_1,\ldots,\theta_k)}$$

Вместо модуля разности можно рассматривать и квадрат разности.

Метод довольно простой и понятный, но требует подбора числа бинов и предсказывает лишь дискретное множество вероятностей.

- **Изотоническая регрессия**. Этот метод похож на предыдущий, только мы будем, во-первых, настраивать и границы $$0=b_0,b_1,\ldots,b_k = 1$$ бинов $$\mathbb{B}_j = \{t \vert  b_{j-1}\leqslant b_j\}$$, а кроме того, накладываем условие $$\theta_1\leqslant\ldots\leqslant\theta_k$$. Искать $$b_j$$ и $$\theta_j$$ мы будем, приближая $$y_i$$ кусочно постоянной функцией $$g$$ от $$q(x_i)$$:

$$\sum_{i=1}^N(y_i - g(q(x_i)))^2\longrightarrow\min_{g}$$

![](images/prob-ML-isotonic.png){: .center style="width:47vw"}

Минимизация осуществляется при помощи pool adjacent violators algorithm, и эти страницы слишком хрупки, чтобы выдержать его формулировку.

- **Калибровка Платта** представляет собой по сути применение сигмоиды поверх другой модели (то есть самый наивный способ получения ''вероятностей''). Более точно, если $$q(x_i)$$ – предсказанная вероятность, то мы полагаем

$$P(y_i = 1\mid x_i) = \sigma(aq(x_i) + b) = \frac1{1 + e^{-aq(x_i) - b}}$$

где $$a$$ и $$b$$ подбираются методом максимального правдоподобия на отложенной выборке:

$$-\sum_{i=1}^N(\vphantom{\frac12}y_i\log(\sigma(q(x_i)) + (1 - y_i)\log(1 - \sigma(aq(x_i) + b)))\longrightarrow\min\limits_{a,b}$$

Для избежания переобучения Платт предлагал также заменить метки $$0$$ и $$1$$ на регуляризованные оценки вероятностей:

$$t_0 = \frac1{\#\{i \vert y_i = 0\} + 2},\quad t_1 = \frac{\#\{i \vert y_i = 1\} + 1}{\#\{i \vert y_i = 1\} + 2}$$

Калибровка Платта неплохо справляется с выколачиванием вероятностей из SVM, но для более хитрых классификаторов может спасовать. В целом, можно показать, что этот метод хорошо работает, если для каждого из истинных классов предсказанные вероятности $$q(x_i)$$ распределы нормально с одинаковыми дисперсиями. Подробнее об этом вы можете почитать в [этой статье](https://research-information.bris.ac.uk/ws/portalfiles/portal/154625753/Full_text_PDF_final_published_version_.pdf). Там же описано обобщение данного подхода – бета-калибровка.

С большим количеством других методов калибровки вы можете познакомиться в [этой статье](https://dyakonov.org/2020/03/27/проблема-калибровки-уверенности)

## Измерение качества калибровки

Калибровочные кривые хорошо показывают, что есть проблемы, но как оценить наши потуги по улучшению предсказания вероятностей? Хочется иметь какую-то численную метрику. Мы упомянем две разновидности, которые по сути являются прямым воплощением описанных выше идей.

- **Expected/Maximum calibration error**. Самый простой способ, впрочем, является наследником идеи с калибровочной кривой. А именно, разобьём отрезок $$[0,1]$$ на бины $$\mathbb{B}_1,\ldots,\mathbb{B}_k$$ по предсказанным вероятностям и вычислим

$$\sum_{j=1}^k\frac{\#\mathbb{B}_j}{N}\left|\overline{y}(\mathbb{B}_j) - \overline{q}(\mathbb{B}_j)\right|$$

или

$$\max\limits_{j=1,\ldots,k}\left|\overline{y}(\mathbb{B}_j) - \overline{q}(\mathbb{B}_j)\right|$$

где $$\overline{y}(\mathbb{B}_j)$$ – среднее значение $$y_i$$, а $$\overline{q}(\mathbb{B}_j)$$ – среднее значение $$q(x_i)$$ для $$x_i$$, таких что $$q(x_i)\in\mathbb{B}_j$$. Проблема этого способа в том, что мы можем очень по-разному предсказывать в каждом из бинов вероятности (в том числе константой) без ущерба для метрики.

- Одна из популярных метрик – это **Brier score**, которая попросту измеряет разницу между предсказанными вероятностями и $$ y_i $$:

$$\sum_{i=1}^N(y_i - q(x_i))^2$$

Казалось бы, в чём смысл? Немного подрастить мотивацию помогает следующий пример. Допустим, наши таргеты совершенно случайны, то есть $$P(y_i = 1 \vert x_i) = P(y_i)$$. Тогда хорошо калиброванный классификатор должен для каждого $$x_i$$ предсказывать вероятность $$\frac12$$; соответственно, его brier score равен $$\frac14$$. Если же классификатор хоть в одной точке выдаёт вероятность $$p>\frac12$$, то в маленькой окрестности он должен выдавать примерно такие же вероятности; поскольку же таргет случаен, локальный кусочек суммы из brier score будет иметь вид $$\frac{N'}{2}p^2 + \frac{N'}{2}(1-p)^2 < \frac{N'}2$$, что хуже, чем получил бы всегда выдающий $$\frac12$$ классификатор.

Не обязательно брать квадратичную ошибку; сгодится и наш любимый log-loss:

$$\sum_{i=1}^N\left(\vphantom{\frac12}y_i\log{q(x_i)} + (1 - y_i)\log(1 - q(x_i))\right)$$

Это же и помогает высветить ограничения подхода, если вспомнить рассуждения о калиброванности логистической регрессии. Для достаточно гладких классификатора и датасета briar score и log-loss будут адекватными средствами оценки, но если нет – возможно всякое.

**Вопрос на засыпку**: а как быть, если у нас классификация не бинарная, а многоклассовая? Что такое хорошо калиброванный классификатор? Как это определить численно? Как заставить произвольный классификатор предсказывать вероятности?

Мы не будем про это рассказывать, но призываем читателя подумать над этим самостоятельно или, например, посмотреть [туториал с ECML KDD 2020](https://classifier-calibration.github.io/).

# Генеративный подход

## Генеративный и дискриминативный подходы к обучению

Классификационные модели, которые мы рассматривали в предыдущих главах, нацелены непосредственно на оценку $P(Y \vert X)$. Такие модели называются **дискриминативными**. К ним относится, например, логистическая регрессия: она предлагает оценку $$ \hat P(y=1 \vert x) = \sigma(w^Tx) $$. В процессе обучения дискриминативные модели подбирают разделяющую поверность (гиперплоскость в случае логистической регрессии). Новые объекты дискриминативная модель классифицирует в зависимости от того, по какую сторону от разделяющей поверности они лежат. Например, обучившись на изображениях домашних кошек (y=0) и рысей (y=1), дискриминативная модель будет определять, новое изображение больше похоже на кошку или на рысь. При этом, если на вход такой модели дать изображение собаки (объект класса, которого не было в обучении, выброс), дискриминативная модель заведомо не сможет обнаружить, что это и не кошка, и не рысь, и отнесёт такой объект к одному из ''знакомых'' ей классов.

В этой главе мы поговорим о другой группе моделей, которые нацелены на оценку $P(X, Y) = P(X \vert Y)P(Y)$. Такая модель описала бы, как обычно выглядят кошки, как они могут выглядеть, а каких кошек точно не бывает. Так же она описала бы и рысей. Она также определила бы по обучающим данным, насколько изображения кошек встречаются чаще, чем изображения рысей, т.е. оценила бы $P(Y)$. Если модель позволила точно оценить распределение $P(X \vert Y)$, с её помощью можно генерировать объекты из этого условного распределения, в нашем примере -- изображения кошек и рысей соответственно. А вместе распределение $P(X, Y)$ дало бы нам возможность генерировать изображения и кошек, и рысей, причём именно в той пропорции, в которой они встречаются в реальном мире. Поэтому модели, оценивающие $P(X, Y)$, называют **генеративными**. Ещё одно достоинство генеративных моделей -- их способность находить выбросы в данных: объект $x$ можно считать выбросом, если $P(x \vert y)$ мало для каждого класса $y$.

Заметим, что находить выбросы с помощью генеративной модели можно и когда класс всего один (т.е. никакие метки классов не доступны). Такая задача называется одноклассовой классификацией. Например, если у нас есть не размеченный датасет с аудиозаписями речи людей, то, обучив на нём генеративную модель, оценивающую в данном случае $P(X \vert Y)=P(X)$, мы сможем для нового аудио $x$ определить, похоже ли оно на аудиозапись человеческой речи (значение $P(x)$ велико), или это что-то другое: синтезированная речь, посторонний шум и т.п. ($P(x)$ мало). Тем не менее, если мы знаем, что "выбросы", с которыми модели предстоит сталкиваться, -- как правило, синтезированная речь, то, дополнив датасет вторым классов, состоящим из синтезированной речи и смоделировав также распределение этого класса, мы можем существенно увеличить качество детектирования таких выбросов.
Чтобы использовать генеративную модель для классификации, необходимо выразить $P(Y \vert X)$ через $P(X \vert Y)$ и $P(Y)$. Сделать это позволяет формула Байеса:

$$
P(y \vert x) = \frac{P(x, y)}{\sum\limits_{y'\in Y} P(y')P(x \vert y')} = \frac{P(y)P(x \vert y)}{\sum\limits_{y'\in Y} P(y')P(x \vert y')}
$$

Классификация в генеративных моделях осуществляется с помощью $$ \textit{байесовского классификатора} $$:

$$a(x) = \arg\max\limits_{y\in Y} P(y \vert x) = \arg\max\limits_{y\in Y} \frac{P(y)P(x \vert y)}{\sum\limits_{y'\in Y} P(y')P(x \vert y')} = \arg\max\limits_{y\in Y} P(y)P(x \vert y)$$

Оценить $P(Y)$, как правило, несложно. Для этого используют частотные оценки, полученные обучающей выборке:

$$\hat P(Y=y) = \frac{\#(Y=y)}{N} \label{eq:class_proba_estimation} \tag{1}$$

Отметим ещё раз, что использование генеративного подхода позволяет внедрять в модель априорные знания о $P(y)$. Это не очень впечатляет, когда речь идёт о бинарной классификации, но всё меняется, если рассмотреть задачу ASR (автоматического распознавания речи), в которой по записи голоса восстанавливается произносимый текст. Таргетами здесь могут быть любые предложения или даже более развёрнутые тексты. При этом размеченных данных (запись, текст) обычно намного меньше, чем доступных текстов, и обученная на большом чисто текстовом корпусе языковая модель, которая будет оценивать вероятность того или иного предложения, может стать большим подспорьем, позволив из нескольких фонетически корректных наборов слов выбрать тот, который в большей степени похож на настоящее предложение.

Но как смоделировать распределение $P(X, Y)$? Пространство всех возможных функций распределения $P(X, Y)$ бесконечномерно, из-за чего оценить произвольное распределение с помощью конечной выборки невозможно. Поэтому перед оценкой $P(X, Y)$ на это распределение накладывают дополнительные ограничения. Некоторые простые примеры таких ограничений мы рассмотрим в следующих разделах.

### Gaussian discriminant analysis
