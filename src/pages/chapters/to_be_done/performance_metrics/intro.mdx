---
title: Измерение производительности обученных решающих правил. (a.k.a. Метрики)
---

# {{page.title}}

{:.no_toc}

- Этот список будет заменен оглавлением, за вычетом заголовка "Contents",
  к которому добавлен класс `no_toc`.
  {:toc}

Говорят, что компьютерная программа обучается на основе опыта E по отношению к некоторой задаче T и некоторой оценке
производительности P, если ее производительность на T, измеренная посредством Р, улучшается с опытом E. Том Митчел, 1997

"Гораздо легче что-то измерить, чем понять, что именно вы измеряете"
Джон Уильям Салливан
( [по И.Е. Куралёнку](https://www.youtube.com/watch?v=JU6cGecm0Xc) )

Вспомним, что объект наших исследований в машинном обучении с учителем это зависимость, которая скрыта в данных,
доступных нам для анализа. С каждым объектом (актом измерения, примером) у нас ассоциированы выходные данные (их еще
называют отклик, целевая переменная, зависимая переменная) и входные данные, из которых мы в процессе **создания
признаков** получаем т.н. признаковое описание объекта (примера).

Мы познакомились с методами обучения (learning algorithm), которые позволяют нам при помощи обучающих данных
построить **решающие правила**, которые должны повторять зависимость, которую содержат пары (признаковое описание,
целевая переменная).

Теперь пришло время остановиться и подробнее изучить вопрос о том, насколько хорошо (качественно) построенное нами
решающее правило.

Из общих соображений ясно, что качество это может иметь много аспектов.

Здесь нам на выручку приходит тот факт, что, скорее всего, задача обучения с учителем у нас возникла не сама по себе, а
в контексте какой-то другой задачи.

Самый простой случай -- мы с вами получили задачу в рамках соревнования по анализу данных. В данном случае устроитель
соревнования за нас уже выбрал ту самую **оценку производительности**, которая упоминалась в цитате Тома Митчела.

Но на практике, скорее всего, имеется какой-то процесс принятия решений, который будет опираться на результаты
предсказаний, полученных при помощи обученного вами решающего правила.

Это может быть решение о том, сколько коробок с бананами нужно завтра привезти в конкретный магазин, чтобы
минимизировать списания товара, который не будет выкуплен и минимизировать ситуацию, когда покупатель к концу дня не
находит желаемый продукт на полке.
Или это должно быть решение следует ли возводить дамбу и если следует, то какой высоты.
Нужно ли направить человека на дополнительный
Или вы хотите увеличить счастье пользователя от работы с вашим сервисом, чтобы он стал лояльным и обеспечивал вам тем
самым стабильный прогнозируемый доход.

В зависимости от задачи может возникать целая иерархия метрик (показатели эффективности иногда называют метриками),
начиная с т.н. бизнес-метрик, которые, как правило, очень тяжело измерить быстро. Каждый уровень иерархии обосновывает в
рамках допущений, почему изменение более низкоуровневой метрики будет сонаправлено с более высокоуровневой.

На нижних этажах этой пирамиды показателей эффективности живут метрики качества предсказания решающих правил и функции
потерь, которые оптимизируются в некоторых алгоритмах машинного обучения при обучении конкретного решающего правила.

**Замечание**.
Теперь можно явно еще раз отметить, что "идеальной" метрики производительности обученного решающего правила не
существует, ибо очень уж различны постановки **надзадач**, в контексте которых может применяться наше обученное решающее
правило.
Но, возможно, мог бы существовать "внутренний" критерий качества предсказаний, вытекающей из какого-то первого
принципа.
Теоремы, доказывающие факт того, что все такие перво принципы равнозначны, авторам курса на текущий момент не известны.

**Напоминание**
Как мы узнали ранее, методы обучения реализуют разные подходы к обучению:

- обучение на основе прироста информации (как в деревьях решений)
- обучение на основе сходства (как в методах ближайших соседей)
- обучение на основе вероятностной модели данных (например, максимизацией правдоподобия)
- обучение на основе ошибок (минимизация эмпирического риска)

И в рамках обучения на основе минимизации ошибок мы уже отвечали на вопрос: как можно штрафовать модель за предсказание
на обучающем объекте.
Во время сведения задачи о построении решающего правила к задаче численной оптимизации, мы вводили понятие функции
потерь и, обычно, объявляли целевой функцией сумму потерь от предсказаний на всех объектах обучающей выборке.

Некоторые из рассмотренных функций потерь можно использовать и в задаче об измерении производительности решающего
правила.

**Замечание.** Мы говорим предсказание, сделанное с помощью решающего правила, но это не обязательно что-то, что
реализуется через какое-то время, как прогноз погоды или прогноз спроса на тот или иной товар. Предсказываться может
любой атрибут, который сложно измерить к текущему моменту. Например, фотография у вас уже есть, а вот кто на ней
изображен вам может сказать человек, или предположить обученное решающее правило.

Еще одна наивная идея, которую следует иметь в виду состоит в том, что наше правило, наша модель, будет ошибаться на
каких-то объектах (причины ошибок могут быть различны). И разные правила будут ошибаться на разных объектах и с разной
степенью.

Наша задача как специалиста по машинному обучению обратиться ко "внешнему" критерию того, какая из моделей для нас более
предпочтительная и измерить эту предпочтительность. Или, как мы говорили ранее, обосновать, что именно выбранная нами
метрика качества сонаправлена с более высокоуровневой бизнес-метрикой.

Тут нужно сказать пару слов о том, что метрики бывают т.н. online и offline.
Online метрики основываются на данных, которые можно собрать с системы, которая работает, основываясь на нашем решающем
правиле.
Offline метрики могут быть получены до введения нашего решающего правила в эксплуатацию. Начиная от наивного
использования заранее известных правильных ответов, до организации сложных процессов разметки результатов работы систем,
на основе вашего решающего правила с привлечением живых людей.
Так, например, поступают поисковые компании, которые предлагают людям оценить качество ранжирования экспериментальной
системы еще до того, как рядовые пользователи увидят эти результаты в обычном порядке.

В данном разделе нас будут интересовать offline метрики без привлечения дополнительной разметки.

К текущему моменту мы готовы к тому, что "метрик" в нашем арсенале будет больше чем одна.
Начнём знакомство с ними.

## TBD

Случаи, когда отклик является категориальной переменной (задача классификации), и когда отклик является вещественной
переменной (задача регрессии), требуют разных метрик.

### Метрики в задачах классификации

Для начала будем говорить только по скалярных откликах.

Случай, когда классов у нас два обычно рассматривается отдельно.

#### Бинарная классификация: случай предсказания метки класса

**Замечание об асимметрии**. Исторически задача бинарной классификации это задача об обнаружении чего-то редкого в большом потоке объектов, например, поиск человека, больного туберкулёзом, по флюорографии. Или задача признания пятна на экране приёмника радиолакационной станции бомбардировщиком, представляющем угрозу охраняемому объекту (в противовес стае гусей).

Поэтому класс, который для нас представляет интерес, называется "положительным", а оставшийся -- "отрицательным"

Для каждого объекта в зависимости от его истинного класса и предсказанного класса возможно 4 варианта. Их придётся
перечислить явно, т.к. в дальнейшем нам потребуются обозначения.

- **TP** Истинно-положительный случай (True Positive). Истинная метка -- "положительный", предсказанный класс "
  положительный"
- **TN** Истинно-отрицательный случай (True Negative). Истинная метка -- "отрицательный", предсказанный класс "
  отрицательный"
- **FP** Ложно-положительный случай (False Positive). Истинная метка -- "отрицательный", предсказанный класс "
  положительный"
- **FN** Ложно-отрицательный случай (False Negative). Истинная метка -- "положительный", предсказанный класс "
  отрицательный"

Т.е. мы оцениваем ответ решающего правила, узнав истинную метку, и даём оценку предсказанию.

Для удобства все эти 4 числа изображают в виде таблицы, которую называют **Confusion matrix** (матрицей ошибок)

(возможно, вы увидели знакомую конструкцию из статистики под
названием [таблица сопряженности](https://ru.wikipedia.org/wiki/%D0%A2%D0%B0%D0%B1%D0%BB%D0%B8%D1%86%D0%B0_%D1%81%D0%BE%D0%BF%D1%80%D1%8F%D0%B6%D1%91%D0%BD%D0%BD%D0%BE%D1%81%D1%82%D0%B8)
, что не должно вас удивлять: мы же хотим понять силу статистической взаимосвязи двух переменных: истинного класса и
предсказанного)

|                  | Прогнозируемый класс + | Прогнозируемый класс - |
| ---------------- | ---------------------- | ---------------------- |
| Истинный класс + | TP                     | FN                     |
| Истинный класс - | FP                     | TN                     |

Приведём пример.
Воспользуемся [Breast cancer wisconsin (diagnostic) dataset](https://scikit-learn.org/stable/datasets/toy_dataset.html#breast-cancer-wisconsin-diagnostic-dataset)
, входящим в состав обучающий наборов данных библиотеки scikit-learn.

Для начала загрузим данные, и воспользуемся т.н. Классификатором-пустышкой.
Это очень полезный инструмент: можно сразу же посмотреть, чему равен показатель эффективности при использовании наивного
решающего правила. (Мы еще вернемся к идее наивного классификатора позднее. Пока все, что нам нужно от данного
классификатора, это предсказания на отложенной выборке)

```python
from sklearn.datasets
import load_breast_cancer the_data
load_breast_cancer()
relabeled_target = 1 - the_data["target"]
# 0 -- "доброкачественный"
# 1 -- "злокачественный"

from sklearn.model_selection import train_test_split
X = the_data["data"]
y = relabeled_target
X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0)
from sklearn.dummy import DummyClassifier

dc_mf = DummyClassifier(strategy="most_frequent")
dc_mf.fit(X_train, y_train)
from sklearn.metrics import confusion_matrix

y_true = y_test y_pred = dc_mf.predict(X_test)
dc_mf_tn, dc_mf_fp, dc_mf_fn, dc_mf_tp = confusion_matrix(y_true, y_pred, labels = [0, 1]).ravel()
```

|                  | Прогнозируемый класс + | Прогнозируемый класс - |
| ---------------- | ---------------------- | ---------------------- |
| Истинный класс + | TP = 0                 | FN = 53                |
| Истинный класс - | FP = 0                 | TN = 90                |

Обучающие данные таковы, что при стратегии **most_frequent** наш классификатор-пустышка все объекты записывает в
отрицательный класс.

Такой наивный результат позволил нам получить минимальный штраф за FP, но и максимальный штраф за TP.

Попробуем улучшить решающее правило и воспользуемся классификатором на основе случайного леса.

```python
from sklearn.ensemble import RandomForestClassifier
rfc = RandomForestClassifier()
rfc.fit(X_train, y_train)
y_true = y_test
y_pred = rfc.predict(X_test)
rfc_tn, rfc_fp, rfc_fn, rfc_tp = confusion_matrix(y_true, y_pred, labels = [0, 1]).ravel()
```

|                  | Прогнозируемый класс + | Прогнозируемый класс - |
| ---------------- | ---------------------- | ---------------------- |
| Истинный класс + | TP = 52                | FN = 1                 |
| Истинный класс - | FP = 4                 | TN = 86                |

При просмотре матрицы ошибок классификатора на основе случайного леса оставляют ощущение, что этот классификатор чему-то
научился, т.к. главная диагональ матрицы стала содержать все объекты из отложенной выборки, за исключением 4 + 1 = 5
объектов (сравните с 0 + 53 объектами классификатора-пустышки, все опухоли объявляющего доброкачественными).

Мы только что неявно вывели другой показатель эффективности: количество ошибочных классификаций, равный сумме
недиагональных элементов. В бинарном случае это FP + FN. Естественным кажется желание нормировать эту величину на сумму
всех элементов, чтобы получить число от 0 до 1.

В результате мы получаем формулу для показателя эффективности **доля ошибочных классификаций**
<<<<<<< develop
=======

<<<<<<< develop
<Math block>
>>>>>>> feat: pass formulas to Math component

=======
>>>>>>> fix: use MathLayout instead Math
$$
ErrorRate = \frac{FP + FN}{ TP + TN + FP + FN}
$$
<<<<<<< develop
=======

<<<<<<< develop
</Math>
>>>>>>> feat: pass formulas to Math component

Можно рассматривать сопряжённый показатель эффективности, который по-английски называется **accuracy**, а на русский
язык переводится как **верность** или **правильность**

<<<<<<< develop
$$
Accuracy = \frac{TP + TN}{ TP + TN + FP + FN} = 1 - ErrorRate
=======
<Math block>

>>>>>>> feat: pass formulas to Math component
=======
Можно рассматривать сопряжённый показатель эффективности, который по-английски называется **accuracy**, а на русский
язык переводится как **верность** или **правильность**

>>>>>>> fix: use MathLayout instead Math
$$
Accuracy = \frac{TP + TN}{ TP + TN + FP + FN} = 1 - ErrorRate
$$

Давайте построим еще один классификатор на основе линейного метода опорных векторов. (Не забудем привести признаки к
единому масштабу, иначе численный алгоритм не сойдется к решению и мы получим гораздо более плохо работающее решающее
правило. Попробуйте проделать это упражнение.)

```python
from sklearn.svm import LinearSVC
from sklearn.preprocessing import StandardScaler
ss = StandardScaler() ss.fit(X_train)
scaled_linsvc = LinearSVC(C=0.01,random_state=42)
scaled_linsvc.fit(ss.transform(X_train), y_train)
y_true = y_test
y_pred = scaled_linsvc.predict(ss.transform(X_test))
tn, fp, fn, tp = confusion_matrix(y_true, y_pred, labels = [0, 1]).ravel()
```

|                  | Прогнозируемый класс + | Прогнозируемый класс - |
| ---------------- | ---------------------- | ---------------------- |
| Истинный класс + | TP = 50                | FN = 3                 |
| Истинный класс - | FP = 1                 | TN = 89                |

Тут мы встречаемся с очевидной вещью: a priori на матрицах размера 2x2 нет отношения порядка.
У нас есть 2 решающих правила. Одно допустило ошибки (FP = 1, FN = 3), а другое (FP = 4, FN = 1).

Какое из них предпочтительней?

Можно пойти по пути упрощения себе жизни и решить, что мы будем использовать матрицу ошибок как "дополнительную
информацию", но вычислять только скалярные показатели эффективности, т.к. на вещественных числах отношение порядка есть.

Тут нужно сделать несколько замечаний.
**Замечание 0.** Нужно помнить, что если мы говорим о скалярном показателе эффективности, то мы всю сложную структуру
ошибок свели к одному числу. Это очень удобно: видеть на индикаторной панели текущее качество вашей модели. Но не стоит
забывать, что у вашей модели есть много аспектов качества.

**Замечание 1.** Мы сравниваем несколько классификаторов на основании их предсказаний на отложенном множестве. Насколько
ошибки данных классификаторов зависят от разбиения исходного набора данных?
Это должно нас привести к важной мысли: раз мы занимаемся процессом оценки качества, то иногда мы будем получать модели,
чьи показатели эффективности мы захотим наречь "статистически" неразличимыми.
**Замечание 2.** Пусть мы учли предыдущее замечание и эти модели действительно "статистически значимо" иначе ошибаются в
разную строну.
Что для нас важнее: уменьшить FP или TN? Нам потребуется внешний критерий в данном месте. Но мы видим, что в текущем
виде введенная нами **доля ошибочных классификаций** не даст нам возможности учесть такого рода предпочтения. Значит нам
необходимо подумать о расширении нашего арсенала показателей эффективности.

##### Точность и полнота

При рассмотрении примера Breast cancer wisconsin (diagnostic) dataset мы не сделали очень важного: мы не посмотрели на соотношение классов в обучающей выборке, хотя неявно сделали это, когда использовали классификатор-пустышку со стратегией most_frequent.
Если бы мы явно посмотрели на соотношение, то увидели, что оно приблизительно 1 к 2.
Поэтому и accuracy у классификатора-пустышки 0.63.
Для сравнения, у случайного леса accuracy 0.965, а у linearSVC 0.972.
Здесь эффект от применения методов машинного обучения виден невооруженным взглядом.

Но если мы рассмотрим ситуацию, когда положительный класс это событие редкое, то ситуация измениться.

Рассмотрим поисковую систему. В нашем хранилище документов многие миллиарды, а релевантных документов к конкретному
поисковому запросу на несколько порядков меньше.

Если бы нас интересовала точности классификатора "по запросу q документ d релевантен", то классификатор-пустышка со
стратегией most_frequent все документы объявит нерелевантными. И точность у такого классификатора будет близка к
единице. Однако это будет обеспечено членом TN, а нас-то, как пользователей интересует TP.

Идея: а давайте построим такие метрики, которые вообще не будут учитывать TN, а будут ориентироваться на TP.

Если мы рассмотрим долю TP серди всех предсказанных положительных классов, то мы получим показатель эффективности,
который называется **точностью** (precision)

<<<<<<< develop
<<<<<<< develop
$$
Precision = \frac{TP}{TP + FP}
=======
<Math block>

>>>>>>> feat: pass formulas to Math component
=======
>>>>>>> fix: use MathLayout instead Math
$$
Precision = \frac{TP}{TP + FP}
$$

Для того, чтобы модель росла по данному показателю эффективности нам необходимо снижать число ложно положительных
срабатываний.

Если мы захотим иметь показатель эффективности, который

- будет штрафовать нас за большое число ложно отрицательных срабатываний
- по-прежнему не будет обращать внимание на TN
  то мы получим **полноту** (recall)
<<<<<<< develop
=======

<<<<<<< develop
<Math block>
>>>>>>> feat: pass formulas to Math component

=======
>>>>>>> fix: use MathLayout instead Math
$$
Recall = \frac{TP}{TP + FN}
$$
<<<<<<< develop
=======

<<<<<<< develop
</Math>
>>>>>>> feat: pass formulas to Math component

=======
>>>>>>> fix: use MathLayout instead Math
Он показывает сколько примеров, которые действительно положительные было предсказано как положительные.

Существует популярный способ скомпоновать их в одну: для этого берут их среднее гармоническое.
Данный показатель эффективности исторически носит название F1-меры (F1-measure).

<<<<<<< develop
<<<<<<< develop
=======
<Math block>

>>>>>>> feat: pass formulas to Math component
=======
>>>>>>> fix: use MathLayout instead Math
$$
F_1 = \frac{2}{\frac{1}{Recall} + \frac{1}{Precision}} = 2 \frac{Recall \cdot Precision }{Recall + Precision} = \frac
{TP} {TP + \frac{FP + FN}{2}}
$$

#### Бинарная классификация: вероятность принадлежности к положительному классу

Мы с вами помним, что модель логистической регрессии по построению моделирует вероятность принадлежности примера к положительному классу.
Другие модели бинарной классификации обычно возвращают свою уверенность в том, что данный объект принадлежит к
положительному классу, но существуют техники, называемые калибровкой
классификатора ([Predicting Good Probabilities With Supervised Learning](https://icml.cc/Conferences/2005/proceedings/papers/079_GoodProbabilities_NiculescuMizilCaruana.pdf))
, которые позволяют преобразовать данную уверенность в оценке вероятности принадлежности к положительному классу.

Если наша задача была в том, чтобы предоставить вероятности, обще приятной мерой качества является логистическая функция
потерь, которую вы изучали раньше, когда говорили об устройстве некоторый методов классификации (например уже
упоминавшейся логистической регрессии).

Но если нашей задачей был именно построение прогноза в терминах метки класса, нам потребуется как-нибудь преобразовать
вероятность принадлежности к положительному классу в одну из двух меток.
Обычно эту задачу решают при помощи порогового правила: вводится порог, при превышении которого объект маркируется
меткой положительного класса.

**Замечание** Если мы захотим выбирать данное пороговое правило с учетом признаков, то у нас возникнет задача обучения
ансамбля типа stacking. Мы не будем касаться этого в данной главе

Чем выше порог отсечения, тем более уверено наше решающее правило в том, что данный объект принадлежит к положительному
классу.

Возникает соблазн сказать, что выбирая более высокий порог отсечения, мы будем растить точность нашего решающего
правила, но терять в полноте.

Так давайте проварьируем все разумные значения порогов и построим на плоскости (точность, полнота) кривую,
параметризованную порогом отсечения.

**TODO нарисовать кривые для классификаторов из примера**
Рассмотрение кривых точности и полноты подобно рассмотрению матрицы ошибок.

Как в случае матрицы ошибок мы перешили к скалярным показателям эффективности, так и в случае с кривой точность-полнота
можно охарактеризовать ее в виде числа.

Рассмотрим площадь под кривой точность-полнота. Получится показатель эффективности, который называется средняя
точность (average precision).
**TODO: добавить что-то про него**

##### TPR/FPR

**Напоминание**
Точность и полноту мы ввели для того, чтобы не обращать внимания на TN. Это помогло нам описать эффективность наших решающих правил по отношению к редкому классу.

В задаче выбора оптимального порога существует способ учесть TN.

Для этого построим кривую в осях TPR/FPR

TPR, как мы помним, это полнота, т.е.

<<<<<<< develop
<<<<<<< develop
$$
TPR = \frac{TP}{P} \frac{TP}{TP + FN}
=======
<Math block>

>>>>>>> feat: pass formulas to Math component
=======
>>>>>>> fix: use MathLayout instead Math
$$
TPR = \frac{TP}{P} \frac{TP}{TP + FN}
$$

А FPR это доля ложно положительных примеров от общего числа отрицательных примеров, т.е.

<<<<<<< develop
<<<<<<< develop
$$
FPR = \frac{FP}{N}= \frac{FP}{FP + TN}
=======
<Math block>

>>>>>>> feat: pass formulas to Math component
=======
>>>>>>> fix: use MathLayout instead Math
$$
FPR = \frac{FP}{N}= \frac{FP}{FP + TN}
$$

Исторически такие кривые возникли под названием кривые рабочей характеристики приёмника (receiver operating
characteristics curve).

Это очень интересный объект, т.к. площадь под данной кривой равно доле верно упорядоченных пар, где первый элемент имеет
положительную метку, а второй -- отрицательную.

Пара объектов называется верно упорядоченной, если вероятность принадлежности к положительному классу у первого элемента
больше вероятности принадлежности положительному классу у второго.

За каждую неверно упорядоченную пару начисляется штраф в 1 балл

В случае, если вероятности равны, то паре начисляется штраф в 0.5 балла.

После чего штрафные баллы суммируются и делятся на число пар.

Полученный показатель эффективности носи название площади под кривой РХП ( AUC ROC ).

**TODO добавить**

#### Много меточная классификация

mark[TODO]

#### Много классовая классификация

mark[TODO]

### Метрики в задачах регрессии

В задачах регрессии целевая метка у нас имеет потенциально бесконечное число значений. И природа этих значений, обычно,
связана с каким-то процессом измерений:

- величина температуры в определенный момент времени на метеостанции
- количество прочтений статьи на сайте
- количество проданных бананов в конкретном магазине, сети магазинов или стране
- дебит добывающей скважины на нефтегазовом месторождении за месяц и т.п.

Мы видим, что иногда метка это целое число, а иногда произвольное вещественное число.

**Замечание**
Обычно случаи целочисленных меток моделируют так, словно это просто обычное вещественное число.

При наивном подходе и метрики качества для таких задач применяются на общей основе.

Т.е. вы можете размышлять о том, что решающее правило A лучше решающего правила B, т.к. его показатель эффективности
лучше, но при этом предсказания у лучшего правила могут быть не целыми. Если в бизнес-задаче ожидается именно
целочисленный ответ, то и оценивать придется какое-то огрубление.

Мораль этого замечания следующая: оценивайте весь каскад решающих правил: и те "внутренние", которые вы получаете в результате обучения, и те "итоговые", которые вы отдаёте бизнес-заказчику.

**Пример**
Вы можете быть удовлетворены, что стали ошибаться не во втором, а только в третьем знаке после запятой, при
предсказании погоды. Но сами погодные данные измеряются с точностью до десятых долей градуса, а пользователь и вовсе
может интересоваться лишь целым числом градусов.

**Напоминание**
Мы смотрим на данные, доступные нам для моделирования, так, словно их породила следующая вероятностная модель:

<<<<<<< develop
<<<<<<< develop
=======
<Math block>

>>>>>>> feat: pass formulas to Math component
=======
>>>>>>> fix: use MathLayout instead Math
$$
y_i = F^{true}(x^{true}_i) + \varepsilon_i,
$$

<<<<<<< develop
<<<<<<< develop
=======
</Math>

>>>>>>> feat: pass formulas to Math component
=======
>>>>>>> fix: use MathLayout instead Math
где $F^{true}$ это истинная детерминированная часть, которая зависит от набора признаков $x^{true}$, измеренных без ошибки, а $\varepsilon_i$ некоторая случайная величина с нулевым матожиданием.

Скорее всего:

- нам не известен набор истинных признаков
- те признаки, которые известны, могут содержать в себе ошибки измерения
- истинная функция детерминированной части зависимости не принадлежит тому классу, среди которого подбирает решающее
  правило выбранный нами алгоритм машинного обучения.

mark[Рисунок 7.2 из ESLII_print12.pdf]

Давайте начнём работать с этим.

Пусть объекты обучающей выборки были описаны признаками $x_i$ и алгоритм обучения обучил решающее правило $a(x_i) = f(
x_i)$.

Величину $$ e_i = f(x_i) - y_i $$ называют **ошибкой на объекте i** или **регрессионным остатком**.

**Замечание**
Тут, как обычно, все определяется с точности до знака. При таком определении положительный остаток означает перепрогноз.
Как обычно: уточняйте термины в вашем конкретном коллективе, чтобы не случалось недопониманий.

Весь набор ошибок на тестовом множестве может служить аналогом матрицы ошибок из задачи классификации в том смысле, что
когда мы рассмтриваем два разных решающих правила, то, глядя на то, как они ошиблись на объектах мы можем прийти к
выводу, что для решения бизнес-задачи нам выгоднее взять ту или иную модель.

Аналогия между вектором ошибок и матрицей ошибок в том, что на векторе сложно построить отношение порядка. И мы можем,
как и в случае с бинарной классификацией начать строить агрегаты от вектора ошибок, получая тем самым разные показатели
эффективности.

И, как и в случае с задачами классификации, нам предстоит отдельно выяснить, какие из этих показателей эффективности
сонаправлены с показателями бизнес-задачи.

#### MSE, RMSE, $R^2$

MSE -- один из самых популярных показателей эффективности. Он уже знаком вам, т.к. применяется в качестве функции потерь (или
входит в ее состав) во многих ранее рассмотренных вами методах.

**Замечание**: Функция потерь это функция в первую очередь от параметров модели, в то время как показатель качества это
функция от векторов истинных меток и предсказанных значений, но формула у них одинаковая. Ситуация аналогично тому, как
правдоподобие и плотность вероятности также имеют одинаковую форму, но разные первоочередные переменные.

$$ MSE(y^{true}, y^{pred}) = \frac{1}{N}\sum_1^N (y_i - f(x_i))^2 $$ иногда для того, чтобы показатель эффективности MSE
имел размерность исходных данных из него извлекают квадратный корень и получают показатель эффективности RMSE.

В таком виде показатель эффективности неограничен сверху. Чтобы нанести некоторую "систему координат", делают следующее:

- Замечают, что наилучшее константное предсказание с точки зрения MSE это среднее арифметическое меток -- $\bar{y}$. (
  Заметтье, чтобы не было подглядывания в test это будут метки из обучающей выборки)
- рассматривают в качестве показателя ошибки $$ R^2 = 1 - \frac{\sum_1^N (y_i - f(x_i))^2}{\sum_1^N (y_i - \bar{y})^2}
  $$

У идеального решающего правила $R^2$ равен 1, у налучшего константного предсказания он равен 0 на обучающей выборке.

mark[Нужно ли про связь с распределением остатков по нормльному законну и сведению ММП к минимизации MSE вспоминать?]

MSE квадратично штрафует за большие ошибки на объектах. Вы уже видели проявление этого при обучении решающих правил
методом минимизации квадратичных ошибок, но там это проявлялось, что решающее правило старалось хорошо подстроится под
выбросы.

Когда же мы ведем речь про показатель эффективности, мы будем предпочитать модели, которые не имеют больших ошибок.

Если большие ошибки для нас действительно неприемлемы, то это даже очень полезное свойство (и его даже можно усиливать,
повышая степень, в которую мы возводим ошибку на объекте), но если, например, у нас появляются "выбросы" в данных, то
модели будут получать на них пеоправданно большой штраф: подстроится под них хорошо все-равно не получится, а ошибка на
таком объекте будет маскирвать различия в ошибках на основном множесте объектов.

Таким образом, сравнивая два решающих правила при помощи MSE у нас выигрывать будет то, у кого меньше ошибка на
объектах-выбросах, а это, скорее всего, не то, чего требует от нас вышестоящая бизнес-задача.

**История про квадратичный штраф за ошибку**
Все действующие лица изменены, но факт остаётся верным:
Из-за неверно введенных данных в качестве метки было введено число в 100 раз превышавшее реальное значение.
Моделировалась величина при помощи градиентного бустинга над деревьями решений. Функция потерь была MSE.

Однажды уже во время эксплуатации случилось ч.п.: у нас появились предсказания в 100 раз превышающие нормальный физический смысл.
Представьте себе, например, что вместо обычных 4 ящиков бананов система предлагала поставить в магазин 400.

Были распечатаны все деревья из ансамбля и мы увидели, что, действительно, постепенно число ящиков увеличивалось до прогнозных 400.

Было решено проверить гипотезу, что был выброс в данных для обучения. Так оно и оказалось: всего одна точка давала такую потерю на объекте,
что алгоритм обучения решил переобучиться под этот выброс, нежели чем смириться с таким штрафом на этом объекте.

А в эксплуатации у нас возникли точки, которые плюс-минус попадали в такие же листья ансамбля, что и объект-выброс.

Предупредить такого рода аварии можно с двух сторон: со стороны контроля качества данных, либо со стороны изменения штрафа.

Аналогично, можно поступать и в случае, когда мы разрабатываем метрику качества: более щадяще штрафовать за ошибку на объекте.

#### MAE, WAPE

Рассмотрим

<<<<<<< develop
<<<<<<< develop
=======
<Math block>

>>>>>>> feat: pass formulas to Math component
=======
>>>>>>> fix: use MathLayout instead Math
$$
MAE(y^{true}, y^{pred}) = \frac{1}{N}\sum_1^N \left|y_i - f(x_i)\right|
$$

<<<<<<< develop
<<<<<<< develop
=======
</Math>

>>>>>>> feat: pass formulas to Math component
=======
>>>>>>> fix: use MathLayout instead Math
Mean absolute error.

В задачах прогнозирования спроса на товары популярна нормированная версия MAE, называемая WAPE.

<<<<<<< develop
<<<<<<< develop
$$
WAPE(y^{true}, y^{pred}) = \frac{\frac{1}{N}\sum_1^N \left|y_i - f(x_i)\right|}{\sum_1^N y_i}
$$
=======
<Math block>

=======
>>>>>>> fix: use MathLayout instead Math
$$
WAPE(y^{true}, y^{pred}) = \frac{\frac{1}{N}\sum_1^N \left|y_i - f(x_i)\right|}{\sum_1^N y_i}
$$

<<<<<<< develop
</Math>
>>>>>>> feat: pass formulas to Math component

=======
>>>>>>> fix: use MathLayout instead Math
Преимущество, разве что в том, что это величина безразмерная.
Если мы предсказываем идеально, то WAPE = 0.
Если все предсказания отдаём нулевыми, то WAPE = 1

**Мотивирующий пример**
И MSE и MAE зависят от ошибок на объектах.
Рассмотрим задачу прогнозирования спроса на следующий месяц.

Пусть у нас есть два продукта: продукт A продаётся в количестве 100 штук, а продукт В в количестве 10 штук.
И пусть базовая модель предсказывает количество продаж продукта A как 98 штук, а продукта B как 8 штук.

Ошибки на этих объектах добавляют 4 штрафных единиы в MAE.

И есть 2 модели-кандидата на улучшение.
Первая предсказывает товар А 99 штук, а товар B 8 штук.
Вторая предсказывает товар А 98 штук, а товар B 9 штук.

С т.з. MAE обе модели улучшают MAE базовой модели на 1 единицу.
Однако, с т.з. бизнес-заказчика может оказаться предпочтительней выбрать вторую модель, т.к. предсказание продажи редкиз тововаров для него может быть приоритетнее.
Один из способов учесть такое требование -- рассматривать относительную ошибку на объектах

#### MAPE, SMAPE

Когда заходит речь об относительных ошибках, сразу возникает вопрос: а что мы будем ставить в знаменатель.

В метрике MAPE -- Mean Absolute Percentage Error в знаменатель помещают целевое значение

<<<<<<< develop
<<<<<<< develop
$$
MAPE(y^{true}, y^{pred}) = \frac{1}{N} \sum_1^N \frac{ \left|y_i - f(x_i)\right|}{y_i}
$$
=======
<Math block>

=======
>>>>>>> fix: use MathLayout instead Math
$$
MAPE(y^{true}, y^{pred}) = \frac{1}{N} \sum_1^N \frac{ \left|y_i - f(x_i)\right|}{y_i}
$$

<<<<<<< develop
</Math>
>>>>>>> feat: pass formulas to Math component

С особыми случаями, когда в знаменателе оказывается 0, обычно, поступают "инженерным" способом: или выдают за непредсказание 0 на таком объекте большой, но фиксированный штраф,
либо пытаются "застраховаться" от подобного на уровне формулы и переходят к метрике SMAPE -- Symmetric Mean Absolute Percentage Error

<<<<<<< develop
$$
SMAPE(y^{true}, y^{pred}) = \frac{1}{N} \sum_1^N \frac{ 2 \left|y_i - f(x_i)\right|}{y_i + f(x_i)}
$$
=======
<Math block>

=======
С особыми случаями, когда в знаменателе оказывается 0, обычно, поступают "инженерным" способом: или выдают за непредсказание 0 на таком объекте большой, но фиксированный штраф,
либо пытаются "застраховаться" от подобного на уровне формулы и переходят к метрике SMAPE -- Symmetric Mean Absolute Percentage Error

>>>>>>> fix: use MathLayout instead Math
$$
SMAPE(y^{true}, y^{pred}) = \frac{1}{N} \sum_1^N \frac{ 2 \left|y_i - f(x_i)\right|}{y_i + f(x_i)}
$$

<<<<<<< develop
</Math>
>>>>>>> feat: pass formulas to Math component

=======
>>>>>>> fix: use MathLayout instead Math
Здесь штраф в случае, когда целевое значение 0 предсказывается 0 можно считать нулевым.

Сделав таким образом переход от абсолютных ошибок на объекте к относительным, мы сделали объекты в тестовой выборке равнозначными:
Даже, если мы делаем абсурдно большое (положительное) предсказание, на фоне которого истинная метка теряется, мы получаем штраф за этот объект порядка 1 в случае MAPE и 2 в случае SMAPE.

#### RMSLE

льтернативные способ уйти от абсолютных ошибок к относитльеным предлагает метрика RMSLE -- Root Mean Squaread Logrithmic Error

<<<<<<< develop
<<<<<<< develop
$$
SMAPE(y^{true}, y^{pred}| c) = \sqrt{ \frac{1}{N} \sum_1^N \log{\left(y_i + c \right)} - \log{\left(f(x_i) + c \right)} }
$$
=======
<Math block>

=======
>>>>>>> fix: use MathLayout instead Math
$$
SMAPE(y^{true}, y^{pred}| c) = \sqrt{ \frac{1}{N} \sum_1^N \log{\left(y_i + c \right)} - \log{\left(f(x_i) + c \right)} }
$$

<<<<<<< develop
</Math>
>>>>>>> feat: pass formulas to Math component

=======
>>>>>>> fix: use MathLayout instead Math
где нормировочная константа $$c$$ вводится искусственно, чтобы не брать логарифм от нуля.
Также, по построению, видно, что метрика пригодна лишь для неотрицательных меток.

mark [Творчески переработать:]
Пример про MAE и RMSE во временных рядах
Ярослав Шмулев - Прогнозирование продаж с использованием методов машинного обучения - DataStart.ru
минута 12
https://youtu.be/Rfa6MTQ2MSs?t=907

#### Веса в метриках

Все вышеописанные метрики легко допускают введение весов для обектов. Например, можно взвешивать на стоимость ошибки на
данном объекте, если мы из каких-то соображений можем ее определить.

#### Доля предсказаний с абсолютными ошибками больше чем d

Еще одним способом охарактеризовать производительность решающего правила в моделях регрессии это вычислить долю предсказаний с абсолютными ошибками больше чем d

$$
Share\_ae\_gth\_d = \frac{1}{N} \sum^N_1  \left[ \left| y_i - f(x_i) \right| > d \right]
$$

Например, можно считать, что прогноз погоды сбылся, если ошибка предскзаания составила меньше 1/2/3 градусов.

Рассматриваемая метрика покажет то, в какой доле случаев прогноз не сбылся.

# Мысли, которые пока не вплетены в текст

## 2020_12_05_metrics.graphml

- Шкала метрик нелинейная, и ее необходимо "осознать"
  - Сравнение с человеческим предсказанием
  - Случайное
  - Наилучшее константное решение
  - Идеальное решение (которое алгоритмически не строится, а просто из разметки выводится)

## Про ансамбли Метрик

Подобно тому, как мы неизвестную зависимость аппроксимируем каким-то эффективно вычислимым решающим правилом из семейства моделей,
мы можем смотреть на базовые метрики, как на строительные кубики и пытаться апроксимировать ими бизнес-метрику.

Цель этой главы была познакомить Вас с основныеми "строительными блоками" метрик, как ранее Вы были ознакомлдены с морделями решающих реревьев или линейными моделями.

Техника раннего останова по validation curve нам в помощь.

## Одна метрика для оптимизации, другие для контроля

Механизм, который я услышал в изложени:
очень хорошо, когда можно двигаться к цели по одной метрике
[Andrew Ng; Single Number Evaluation Metric (C3W1L03)](https://www.youtube.com/watch?v=sofffBNhVSo)
Но, как шутил Роман Поборчий: только точность накрутишь -- полнота никакая.
И что делать, если переход к F1-мере не даёт удовлетврительных результатов?

Например в задачах поставки продуктов нам хочется, чтобы и "точность" предсказания была как можно лучше, но при этом мы не сказывались в наивное решение "недопрогнозируй, создавая дефицит, ибо тогда выкупят всё".
Т.е. у нас есть метрики двух сортов: одна безусловная, по которой мы стараемся получить лучшее значение, и набор вспомогательных, котрые задают ограничения на наше решение.
Bndrew Ng в своём [видео (C3W1L04)](https://www.youtube.com/watch?v=BH9mlmdXzzI) называет из Satisficing and Optimizing Metrics.

## Метрики качества vs функция потрери/штрафа от предскеазания на объекте

Возможно, что-то про это есть в
[Видео К.В. Воронцов "Обзор постановок оптимизационных задач машинного обучения"](https://www.youtube.com/watch?v=tX_MeIbfEmw)

## Как смотреть на метрики

На метрики можно смотреть как на абстрактный показатель эффективности. Если метрика имеет смысл качества, то чем она больше, тем лучше.
(Если метрика имеет смысл числа ошибок, то все наоборот.)

Если метрика ограничена, то можно вводить нормировку, как делают с nDCG в ранжировании.

А можно смотреть на метрику качества, как на оценку потери на вновь предъявляемом объекте.
Ясно, что для этого случая строить метрику нужно особым способом.

## Следующая мысль

# Идеи по структуре изложения

- У Б.Г. Миркина в учебнике "Введение в анализ данных" изложение разделено на три линии: "представление", "формулировка".
  - "Представление" не содержит математических формул и на конкретных данных показывает задачу, метод ее решения, а также комментарии к результатам, когда это необходимо.
  - В "формулировке" сосредоточены все математические детали постановки задачи и метода
  - В "вычислении" объясняется, как провести вычисление при помощи вычислительной среды

# Вопросы:

- Как оглавление и гиперссылки создавать по якорям в md + jekyll
- Как добавлять вертикальные пробелы в сгенерированный html?

# Обзор литературы

# Лекции

[Машинное обучение 1, лекция 5 — метрики качества классификации](https://www.youtube.com/watch?v=3Qj87xe3Djk)

- почему MAE устойчивее чем MSE

## [0073] ISBN 978-5-97060-273-7 Машинное обучение. Наука и искусство построения алгоритмов, которые извлекают знания из данных.

рисунок 2.7
многоклассовый auc стр. 102

## [0095] ISBN 978-5-496-02989-6 Машинное обучение

# Шпаргалка:

Раздел, где сухо и по делу изложены формулы метрик.
Нужен ли такой?

# Подвал:

Позволим себе вольность поддаться духу нашего эпиграфа и заглянем на
страницу [Metrics and scoring: quantifying the quality of predictions](https://scikit-learn.org/stable/modules/model_evaluation.html)
из репозитория описания популярного пакета для Машинного Обучения с открытым кодом scikit-learn.

mark[так можно заметки оставлять, чтобы они в глаза бросались ]

> Originally written with [StackEdit](https://stackedit.io/).
